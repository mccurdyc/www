---
title: Bookshelf
comments: false
---

# 2019

{{% book title="Close to the Machine: Technophilia and Its Discontents" author="Ellen Ullman" finished="March 22, 2019" amazon="https://www.amazon.com/Close-Machine-Technophilia-Its-Discontents/dp/1250002486" thrift="https://www.thriftbooks.com/w/close-to-the-machine-technophilia-and-its-discontents_ellen-ullman/392556/all-editions/" %}}

Founding father of virtual reality, [Jaron Lanier](http://www.jaronlanier.com/), writes
in the introduction about what "nerdism" is like. Lanier says,

> "Life becomes a problem-solving activity, and the problem is some sort of lack of optimization."

He also mentions that computers have this uncanny ability to create the illusion
that we are all-seeing. This immediately made me think about how social media
has the ability to polarize groups of users, especially in regards to American politics. [This
post](https://greatergood.berkeley.edu/article/item/is_social_media_driving_political_polarization)
from the Greater Good Magazine, explains that the polarization may be subtler than
we think, but major social media sites are not actively working to "bridge" the
polarized groups, to fix the problem.

As software engineers, we have a lot of power and with that comes a lot of responsibility.
However, sometimes lives or data companies are responsible for is not handled with
the appropriate care. Think of the [recent issues with Boeing's best-selling, 737, planes](https://www.cnbc.com/2019/03/25/boeing-readies-software-fix-for-737-max-planes-airlines-prepare-for-longer-disruptions.html)
where the software has actually caused the planes to crash in an attempt to
keep the planes from stalling or the [Equifax breach in 2017](https://www.ftc.gov/equifax-data-breach)
where sensitive personal information of 143 million Americans was exposed. Some
of this could be due to strict deadlines to ship imposed on software engineers or
the lack of understanding or care by engineers about what they are actually building.

Ullman describes the typical thought of how software is created, that is, via a
"black-box", where software is magically produced. "Then it moves to programming."
As software engineers, sometimes we are too caught up in _how_ we build something,
instead of _what_ we are building. Ullman says,

> It has occurred to me that if people really knew how software got written, I'm not
> sure if they'd give their money to a bank or get on am airplane ever again.

Ullman also mentions that in general the culture around building software is to make
money, not to solve "real", social problems. And that when we do build software to
solve social problems, we force users to conform to how we think the problem should
be solved instead of talking to the users of the software. We, as software engineers,
are obsessed with problem solving and therefore think we can come up with a better
solution, sometimes without talking to the end-users.

Software systems force users to conform to a limited set of defined options by the
owners of the systems, e.g., male, female.

> ...the more we surround ourselves with a narrowed notion of existence, the more narrow
> existence becomes. We conform to the range of motion the system allows. We must
> be more orderly, more logical. Answer the question, Yes or No, OK or Cancel.

As software engineers, we take the malfunctioning of software as personal slight,
cursing at the engineers before us who wrote the broken code that we have now
inherited. "How could you be so blind?".

This is something recently that I have talked
about with peers. While a system may be poorly written or buggy --- are you sure it's
a bug and wasn't a feature at that time? --- you have to consider when it was written.
The constraints, the pressures, the discussions and resources available. While
many of these things should be documented, that is not always feasible or seen as
a good use of time when making the decisions. You, as the creator of future loathed
code, need to defend your future self. The blame should not be put entirely on you,
just because you are the name in the commit log.

Something that I have already had to fight with is individuals or groups of individuals
who are attached to a single technology, wanting to use it as a universal solution,
even when there are much better alternatives.

Ullman says when discussing attachment to a single technology, "Don't get comfortable, don't
get too attached, don't get married. Fidelity in technology is not even desirable.
Loyalty to one system if career-death."

Finally, the following paragraph resonated with me, where Ullman describe the life
of a software engineer, we are "never not working".

> Even when I'm not actually doing something that could be called work, I might get
> started any minute. So everything is an interruption --- a call from a friend,
> an invitation to lunch --- everything must be refused because it is possible that
> from one moment to the next I will get back to something.

{{% /book %}}

---

{{% book title="Life in Code" author="Ellen Ullman" finished="March 05, 2019" amazon="https://www.amazon.com/Life-Code-Personal-History-Technology/dp/1250181690/ref=pd_lpo_sbs_14_t_0?_encoding=UTF8&psc=1&refRID=6BC2NWZG60SW5CTFWQMG" thrift="https://www.thriftbooks.com/w/life-in-code-a-personal-history-of-technology_ellen-ullman/13998458/all-editions/" %}}

Ullman starts the book with the following quote,

> People imagine that programming is logical, a process like fixing a clock. Nothing
> could be further from the truth. Programming is more like an illness, a fever, an obsession.
> It's like riding a train and never being able to get off.

She goes on to describe her interactions with technologies of the times and
her experiences as a female software engineer in a male-dominated industry. She
discusses this notion of "being close to the machine" --- writing code that is
less abstracted from machine-readable code --- and how that the individuals that write
less abstracted code are respected because they are quirkier. Ellen mentions the
biases and culture that are assumed; the optimizations in every part of life, as
if life is a piece of software (e.g., reducing time spent cooking, etc.).

The internet further polarizes the thoughts of individuals, because now, they
can dive deeper into the parts of the web that they choose.

> Before the advent of the web, if you wanted to sustain a belief in far-fetched
> ideas, you had to go out into the desert, or live on a compound in the mountains...
> But now, without leaving home, from the comfort of your easy chair, you can divorce
> yourself from the consensus of what constitutes "truth".

Even the founders of the internet were upset with how it evolved into something
very different from what it was intended.

> ... we must find our way back to the technologists' dream of the internet, the
> free exchange among millions of equals; the following of links to links, unobserved...

> The internet had become not a celebration of computing, but a stock-market event, as
> Tim Berners-Lee had feared it would.


She discusses an inner battle with the infamous imposter syndrome, when she was offered
a job from her friend's brother, Larry Page of Google. And how she convinced herself
that her self-taught knowledge was not adequate and that she would be revealed as as fraud.

She considers "programming the post-human" and what it truly means to be a fleshy human.
The post-human will not appreciate deceptively simple things such as chairs that
provide comfort for a tired human.

> Intelligence, then, is a consequence of our having this particular fleshly form...

Ullman alludes to the software that makes the pieces of our lives such as dinner and meals
seem like an inconvenience. We are constantly trying to optimize away these important
parts of life that define us as humans.

> Our appetites have given way to theirs. Robots aren't becoming us, ...we are becoming
> them.

Finally, she calls to the general public to learn how to program, not to become
professional programmers, but to loosen the stranglehold of code that surrounds us
to,

> pierce the computing veil; to demystify algorithms; to know that code has
> biases, [and] that programs are written by human beings...

> For the world of programmers is not going to change on its own. Many who enter are
> going to find themselves in the company of ...men who want to humiliate the newcomers,
> ...men who will not or cannot communicate.

But, Ullman urges "outsiders" to penetrate the bubble because there is so much
to be found in yourself and with those encouraging you when you are working
toward getting a piece of software to "just work".

> Yet I must force myself to see the good the young dreamers might do.
> I must hope that those who barely remember life before the internet, or never knew
> it at all, will find their way through the dazzle and disappointments of technology,
> the seductions and the traps.

{{% /book %}}
